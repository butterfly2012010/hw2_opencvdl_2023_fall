# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'hw2.ui'
#
# Created by: PyQt5 UI code generator 5.15.10
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


# from PyQt5 import QtCore, QtGui, QtWidgets
from math import e
import sys
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QLabel, QFileDialog, QGraphicsScene, QGraphicsView
from PyQt5.QtGui import QPainter, QPixmap, QImage, QPen

import cv2
import numpy as np
from matplotlib import pyplot as plt

import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.models import resnet50
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchsummary import summary
# import matplotlib.pyplot as plt
from tqdm import tqdm

from PIL import Image, ImageQt




class Ui_Form(object):
    def __init__(self, Form):
        self.setupUi(Form)
        self.retranslateUi(Form)

        # 1. Hough Circle Transform
        self.n_coins = 0
        self.DrawContour.clicked.connect(self.q1_1)
        self.CountCoins.clicked.connect(self.q1_2)

        # 2. Histogram Equalization
        self.HistogramEqualization.clicked.connect(self.q2)

        # 3. Morphology Operation
        self.Closing.clicked.connect(self.q3_1)
        self.Opening.clicked.connect(self.q3_2)

        # 4. MNIST Classifier Using VGG19
        self.ShowModelStructure.clicked.connect(self.q4_1)
        self.ShowAccAndLoss.clicked.connect(self.q4_2)
        self.Predict.clicked.connect(self.q4_3)

        # 5. ResNet50
        self.LoadImage.clicked.connect(self.LoadImageDataset)
        self.ShowImages.clicked.connect(self.q5_1)
        self.ShowModelStructure_4.clicked.connect(self.q5_2)
        self.ShowComparison.clicked.connect(self.q5_3)
        self.Inference.clicked.connect(self.q5_4)



    def setupUi(self, Form):
        Form.setObjectName("Form")
        Form.resize(926, 733)
        self.groupBox = QtWidgets.QGroupBox(Form)
        self.groupBox.setGeometry(QtCore.QRect(120, 30, 211, 151))
        self.groupBox.setObjectName("groupBox")
        self.DrawContour = QtWidgets.QPushButton(self.groupBox)
        self.DrawContour.setGeometry(QtCore.QRect(50, 30, 111, 23))
        self.DrawContour.setObjectName("DrawContour")
        self.CountCoins = QtWidgets.QPushButton(self.groupBox)
        self.CountCoins.setGeometry(QtCore.QRect(50, 80, 111, 23))
        self.CountCoins.setObjectName("CountCoins")
        self.CountCoinsText = QtWidgets.QLabel(self.groupBox)
        self.CountCoinsText.setGeometry(QtCore.QRect(30, 120, 161, 20))
        self.CountCoinsText.setObjectName("CountCoinsText")
        self.groupBox_2 = QtWidgets.QGroupBox(Form)
        self.groupBox_2.setGeometry(QtCore.QRect(120, 210, 211, 81))
        self.groupBox_2.setObjectName("groupBox_2")
        self.HistogramEqualization = QtWidgets.QPushButton(self.groupBox_2)
        self.HistogramEqualization.setGeometry(QtCore.QRect(34, 30, 151, 23))
        self.HistogramEqualization.setObjectName("HistogramEqualization")
        self.groupBox_3 = QtWidgets.QGroupBox(Form)
        self.groupBox_3.setGeometry(QtCore.QRect(120, 310, 211, 111))
        self.groupBox_3.setObjectName("groupBox_3")
        self.Closing = QtWidgets.QPushButton(self.groupBox_3)
        self.Closing.setGeometry(QtCore.QRect(40, 30, 141, 23))
        self.Closing.setObjectName("Closing")
        self.Opening = QtWidgets.QPushButton(self.groupBox_3)
        self.Opening.setGeometry(QtCore.QRect(40, 70, 141, 23))
        self.Opening.setObjectName("Opening")
        self.groupBox_4 = QtWidgets.QGroupBox(Form)
        self.groupBox_4.setGeometry(QtCore.QRect(360, 30, 531, 311))
        self.groupBox_4.setObjectName("groupBox_4")
        self.ShowModelStructure = QtWidgets.QPushButton(self.groupBox_4)
        self.ShowModelStructure.setGeometry(QtCore.QRect(30, 40, 131, 21))
        self.ShowModelStructure.setObjectName("ShowModelStructure")
        self.ShowAccAndLoss = QtWidgets.QPushButton(self.groupBox_4)
        self.ShowAccAndLoss.setGeometry(QtCore.QRect(30, 80, 131, 21))
        self.ShowAccAndLoss.setObjectName("ShowAccAndLoss")
        self.Predict = QtWidgets.QPushButton(self.groupBox_4)
        self.Predict.setGeometry(QtCore.QRect(30, 120, 131, 21))
        self.Predict.setObjectName("Predict")
        self.Reset = QtWidgets.QPushButton(self.groupBox_4)
        self.Reset.setGeometry(QtCore.QRect(30, 160, 131, 21))
        self.Reset.setObjectName("Reset")
        self.painter = QtWidgets.QLabel(self.groupBox_4)
        self.painter.setGeometry(QtCore.QRect(220, 40, 261, 241))
        self.painter.setObjectName("painter")
        self.groupBox_5 = QtWidgets.QGroupBox(Form)
        self.groupBox_5.setGeometry(QtCore.QRect(360, 360, 531, 311))
        self.groupBox_5.setObjectName("groupBox_5")
        self.ShowImages = QtWidgets.QPushButton(self.groupBox_5)
        self.ShowImages.setGeometry(QtCore.QRect(30, 80, 131, 21))
        self.ShowImages.setObjectName("ShowImages")
        self.ShowModelStructure_4 = QtWidgets.QPushButton(self.groupBox_5)
        self.ShowModelStructure_4.setGeometry(QtCore.QRect(30, 120, 131, 21))
        self.ShowModelStructure_4.setObjectName("ShowModelStructure_4")
        self.ShowComparison = QtWidgets.QPushButton(self.groupBox_5)
        self.ShowComparison.setGeometry(QtCore.QRect(30, 160, 131, 21))
        self.ShowComparison.setObjectName("ShowComparison")
        self.Inference = QtWidgets.QPushButton(self.groupBox_5)
        self.Inference.setGeometry(QtCore.QRect(30, 200, 131, 21))
        self.Inference.setObjectName("Inference")
        self.LoadImage = QtWidgets.QPushButton(self.groupBox_5)
        self.LoadImage.setGeometry(QtCore.QRect(30, 40, 131, 21))
        self.LoadImage.setObjectName("LoadImage")
        self.ShowLoadedImage = QtWidgets.QGraphicsView(self.groupBox_5)
        self.ShowLoadedImage.setGeometry(QtCore.QRect(210, 40, 291, 221))
        self.ShowLoadedImage.setObjectName("ShowLoadedImage")
        self.scene = QGraphicsScene()
        self.ShowLoadedImage.setScene(self.scene)
        # self.ShowLoadedImage.setAlignment(QtCore.Qt.AlignCenter)
        # self.ShowLoadedImage.show()
        self.PredictionResult = QtWidgets.QLabel(self.groupBox_5)
        self.PredictionResult.setGeometry(QtCore.QRect(310, 270, 91, 20))
        self.PredictionResult.setObjectName("PredictionResult")

        self.retranslateUi(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate("Form", "hw2"))
        self.groupBox.setTitle(_translate("Form", "1. Hough Circle Transform"))
        self.DrawContour.setText(_translate("Form", "1.1 Draw Contour"))
        self.CountCoins.setText(_translate("Form", "1.2 Count Coins"))
        self.CountCoinsText.setText(_translate("Form", "There are _ coins in the image."))
        self.groupBox_2.setTitle(_translate("Form", "2. Histogram Equalization"))
        self.HistogramEqualization.setText(_translate("Form", "2. Histogram Equalization"))
        self.groupBox_3.setTitle(_translate("Form", "3. Morphology Operation"))
        self.Closing.setText(_translate("Form", "3.1 Closing"))
        self.Opening.setText(_translate("Form", "3.2 Opening"))
        self.groupBox_4.setTitle(_translate("Form", "4. MNIST Classifier Using VGG19"))
        self.ShowModelStructure.setText(_translate("Form", "1. Show Model Structure"))
        self.ShowAccAndLoss.setText(_translate("Form", "2. Show Acc and Loss"))
        self.Predict.setText(_translate("Form", "3. Predict"))
        self.Reset.setText(_translate("Form", "4. Reset"))
        self.painter.setText(_translate("Form", "TextLabel"))
        self.groupBox_5.setTitle(_translate("Form", "5. ResNet50"))
        self.ShowImages.setText(_translate("Form", "5.1 Show Images"))
        self.ShowModelStructure_4.setText(_translate("Form", "5.2 Show Model Structure"))
        self.ShowComparison.setText(_translate("Form", "5.3 Show Comparison"))
        self.Inference.setText(_translate("Form", "5.4 Inference"))
        self.LoadImage.setText(_translate("Form", "Load Image"))
        self.PredictionResult.setText(_translate("Form", "Prediction:"))



    def q1_1(self):
        # import cv2
        # import numpy as np
        # from matplotlib import pyplot as plt

        # 1-1
        # Load the image
        options = QtWidgets.QFileDialog.Options()
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(None, "Open Image", "", "All Files (*);;JPEG (*.jpg);;PNG (*.png)", options=options)
        # image = cv2.imread('/content/coins.jpg')
        image = cv2.imread(fileName)
        original_image = image.copy()
        processed_image = image.copy()
        circle_center_image = image.copy()

        # Convert to grayscale
        gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)

        # Remove noise
        gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # Circle detection
        circles = cv2.HoughCircles(gray_blurred,
                    cv2.HOUGH_GRADIENT, 1, 20,
                    param1=50, param2=30, minRadius=10, maxRadius=30)

        # Ensure at least some circles were found
        if circles is not None:
            # Convert the (x, y) coordinates and radius of the circles to integers
            circles = np.round(circles[0, :]).astype("int")

            # Loop over the (x, y) coordinates and radius of the circles
            for (x, y, r) in circles:
                # Draw the circle in the output image
                cv2.circle(processed_image, (x, y), r, (0, 255, 0), 2)
                # Draw the center of the circle
                cv2.circle(circle_center_image, (x, y), 2, (0, 0, 255), 2)

        # Display the images
        fig, ax = plt.subplots(1, 3, figsize=(15, 5))
        ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
        ax[0].set_title('Original Image')
        ax[0].axis('off')

        ax[1].imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
        ax[1].set_title('Processed Image')
        ax[1].axis('off')

        ax[2].imshow(cv2.cvtColor(circle_center_image, cv2.COLOR_BGR2RGB))
        ax[2].set_title('Circles Center Detected')
        ax[2].axis('off')

        plt.show()

        # 1-2
        # Count how many coins in the image
        self.n_coins = circles.shape[0]

    def q1_2(self):
        self.CountCoinsText.setText(f"There are {self.n_coins} coins in the image.")

    def q2(self):
        # import cv2
        # import numpy as np
        # from matplotlib import pyplot as plt
        # from tkinter import filedialog
        # from tkinter import Tk


        # # opencv api function
        # import cv2
        # import numpy as np
        # from matplotlib import pyplot as plt

        # 讀取圖像
        options = QtWidgets.QFileDialog.Options()
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(None, "Open Image", "", "All Files (*);;JPEG (*.jpg);;PNG (*.png)", options=options)
        # img_path = '/content/histoEqualGray2.png'
        img_path = fileName
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        # 執行直方圖均衡化
        img_eq = cv2.equalizeHist(img)

        # 計算兩個圖像的直方圖
        hist_original = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()
        hist_equalized = cv2.calcHist([img_eq], [0], None, [256], [0, 256]).flatten()

        # # 顯示圖像和直方圖
        # plt.figure(figsize=(10, 8))

        # # 顯示原始圖像
        # plt.subplot(221), plt.imshow(img, 'gray'), plt.title('Original Image')

        # # 顯示均衡化圖像
        # plt.subplot(222), plt.imshow(img_eq, 'gray'), plt.title('Equalized Image')

        # # 顯示原始圖像的直方圖
        # plt.subplot(223), plt.bar(range(256), hist_original), plt.title('Histogram of Original')

        # # 顯示均衡化圖像的直方圖
        # plt.subplot(224), plt.bar(range(256), hist_equalized), plt.title('Histogram of Equalized')

        # # 顯示圖形
        # plt.tight_layout()
        # # plt_path = '/mnt/data/histogram_equalization_result.png'
        # # plt.savefig(plt_path)
        # plt.show()

        # plt_path


        # manual
        # 計算直方圖並正規化以獲得 PDF
        hist, bins = np.histogram(img.flatten(), 256, [0, 256])
        pdf = hist / sum(hist)

        # 計算 CDF
        cdf = pdf.cumsum()
        cdf_normalized = cdf * hist.max()/ cdf.max()

        # 使用 CDF 值創建查找表
        cdf_m = np.ma.masked_equal(cdf, 0)
        cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())
        cdf_final = np.ma.filled(cdf_m,0).astype('uint8')

        # 應用查找表
        img_eq_manual = cdf_final[img]

        # 計算手動均衡化後的直方圖
        hist_manual_eq = cv2.calcHist([img_eq_manual], [0], None, [256], [0, 256]).flatten()

        # 顯示手動均衡化的結果
        plt.figure(figsize=(15, 8))

        # 顯示原始圖像
        plt.subplot(231), plt.imshow(img, 'gray'), plt.title('Original Image')

        # 顯示均衡化圖像
        plt.subplot(232), plt.imshow(img_eq, 'gray'), plt.title('Equalized Image')

        # 顯示手動均衡化圖像
        plt.subplot(233), plt.imshow(img_eq_manual, 'gray'), plt.title('Manually Equalized Image')

        # 顯示原始圖像的直方圖
        plt.subplot(234), plt.bar(range(256), hist_original), plt.title('Histogram of Original')

        # 顯示均衡化後的直方圖（使用 OpenCV）
        plt.subplot(235), plt.bar(range(256), hist_equalized), plt.title('Histogram of Equalized')

        # 顯示手動均衡化後的直方圖
        plt.subplot(236), plt.bar(range(256), hist_manual_eq), plt.title('Histogram of Manually Equalized')

        # 顯示圖形
        plt.tight_layout()
        # plt_path_manual = '/mnt/data/histogram_manual_equalization_result.png'
        # plt.savefig(plt_path_manual)
        plt.show()

        # plt_path_manual

    def q3_1(self):
        # Load the image
        options = QtWidgets.QFileDialog.Options()
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(None, "Open Image", "", "All Files (*);;JPEG (*.jpg);;PNG (*.png)", options=options)
        # image_path = 'E:/YN/opencvdl/Hw2/Dataset_OpenCvDl_Hw2/Q3/closing.png'
        image_path = fileName
        image = cv2.imread(image_path)

        # Convert to grayscale
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Binarize the image
        _, binarized_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)

        # Padding the image with zeros
        kernel_size = 3
        padded_image = np.pad(binarized_image, ((kernel_size//2, kernel_size//2), (kernel_size//2, kernel_size//2)), mode='constant', constant_values=0)

        # Function to perform dilation
        def dilate(image, kernel_size):
            structure_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)
            image_height, image_width = image.shape
            dilated_image = np.zeros_like(image)
            
            for i in range(kernel_size//2, image_height - kernel_size//2):
                for j in range(kernel_size//2, image_width - kernel_size//2):
                    region = image[i - kernel_size//2:i + kernel_size//2 + 1, j - kernel_size//2:j + kernel_size//2 + 1]
                    dilated_image[i, j] = np.max(region * structure_element)
            return dilated_image

        # Function to perform erosion
        def erode(image, kernel_size):
            structure_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)
            image_height, image_width = image.shape
            eroded_image = np.zeros_like(image)
            
            for i in range(kernel_size//2, image_height - kernel_size//2):
                for j in range(kernel_size//2, image_width - kernel_size//2):
                    region = image[i - kernel_size//2:i + kernel_size//2 + 1, j - kernel_size//2:j + kernel_size//2 + 1]
                    eroded_image[i, j] = np.min(region * structure_element)
            return eroded_image

        # Perform dilation
        dilated_image = dilate(padded_image, kernel_size)

        # Perform erosion
        closed_image = erode(dilated_image, kernel_size)

        # Remove padding from the closed image
        final_image = closed_image[kernel_size//2:-kernel_size//2, kernel_size//2:-kernel_size//2]

        # Display the image
        plt.imshow(final_image, cmap='gray')
        plt.title('Closed Image')
        plt.axis('off')
        plt.show()

    def q3_2(self):
        # Load the image for the opening operation
        options = QtWidgets.QFileDialog.Options()
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(None, "Open Image", "", "All Files (*);;JPEG (*.jpg);;PNG (*.png)", options=options)
        # image_path_opening = 'E:/YN/opencvdl/Hw2/Dataset_OpenCvDl_Hw2/Q3/opening.png'
        image_path_opening = fileName
        image_opening = cv2.imread(image_path_opening)

        # Convert to grayscale
        gray_image_opening = cv2.cvtColor(image_opening, cv2.COLOR_BGR2GRAY)

        # Binarize the image
        _, binarized_image_opening = cv2.threshold(gray_image_opening, 127, 255, cv2.THRESH_BINARY)

        # Padding the image with zeros
        kernel_size = 3
        padded_image_opening = np.pad(binarized_image_opening, ((kernel_size//2, kernel_size//2), (kernel_size//2, kernel_size//2)), mode='constant', constant_values=0)

        # Perform erosion followed by dilation to perform opening operation
        # We can use the previously defined erode and dilate functions
        # Function to perform dilation
        def dilate(image, kernel_size):
            structure_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)
            image_height, image_width = image.shape
            dilated_image = np.zeros_like(image)
            
            for i in range(kernel_size//2, image_height - kernel_size//2):
                for j in range(kernel_size//2, image_width - kernel_size//2):
                    region = image[i - kernel_size//2:i + kernel_size//2 + 1, j - kernel_size//2:j + kernel_size//2 + 1]
                    dilated_image[i, j] = np.max(region * structure_element)
            return dilated_image

        # Function to perform erosion
        def erode(image, kernel_size):
            structure_element = np.ones((kernel_size, kernel_size), dtype=np.uint8)
            image_height, image_width = image.shape
            eroded_image = np.zeros_like(image)
            
            for i in range(kernel_size//2, image_height - kernel_size//2):
                for j in range(kernel_size//2, image_width - kernel_size//2):
                    region = image[i - kernel_size//2:i + kernel_size//2 + 1, j - kernel_size//2:j + kernel_size//2 + 1]
                    eroded_image[i, j] = np.min(region * structure_element)
            return eroded_image

        # Perform erosion
        eroded_image_opening = erode(padded_image_opening, kernel_size)

        # Perform dilation
        opened_image = dilate(eroded_image_opening, kernel_size)

        # Remove padding from the opened image
        final_image_opening = opened_image[kernel_size//2:-kernel_size//2, kernel_size//2:-kernel_size//2]

        # Display the image
        plt.imshow(final_image_opening, cmap='gray')
        plt.title('Opened Image')
        plt.axis('off')
        plt.show()

    def q4_1(self):
        # 加載並修改 VGG19 模型
        model = models.vgg19_bn(pretrained=False)
        model.features[0] = nn.Conv2d(1, 64, kernel_size=3, padding=1) # 更改為單通道輸入
        model.classifier[6] = nn.Linear(4096, 10)  # 修改最後一層為 10 個輸出

        # load the trained model parameters
        model.load_state_dict(torch.load('best_vgg19_bn_mnist.pth'))

        # print the model structure using the summary function
        summary(model, (1, 32, 32), device='cpu')

    def q4_2(self):
        # load vgg19_bn_mnist.jpg
        options = QtWidgets.QFileDialog.Options()
        fileName, _ = QtWidgets.QFileDialog.getOpenFileName(None, "Open Image", "", "All Files (*);;JPEG (*.jpg);;PNG (*.png)", options=options)

        # use PIL to plot the image from fileName
        with Image.open(fileName) as image:
            image.show()

    def q4_3(self):
        pass

    def LoadImageDataset(self):
        # load image dataset
        # dataset file sturcture
        # Dataset_OpenCvDl_Hw2
        # |--Q5
        #     |--inference_dataset
        #         |--0.jpg
        #         |--1.jpg
        #         |--2.jpg
        #         |--......

        # load the image dataset
        # use pyqt5 to load an image
        self.imagePath, _ = QtWidgets.QFileDialog.getOpenFileName()
        if self.imagePath:
            self.inputImage = cv2.imread(self.imagePath)
            self.inputImage = cv2.cvtColor(self.inputImage, cv2.COLOR_BGR2RGB)

            self.currentImage = QPixmap(self.imagePath).scaled(224, 224)
            self.scene.addPixmap(self.currentImage)
            self.ShowLoadedImage.fitInView(self.scene.itemsBoundingRect())

    def q5_1(self):
        dataset_path = QtWidgets.QFileDialog.getExistingDirectory()
        # dataset_path = 'E:/YN/opencvdl/Hw2/Dataset_OpenCvDl_Hw2_Q5/dataset'
        transform = transforms.Compose([
            transforms.Resize(224),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            # transforms.Normalize((0.5,), (0.5,))
        ])
        inference_dataset = torchvision.datasets.ImageFolder(
            # root=f"{dataset_path}/inference_dataset", 
            root=dataset_path, 
            transform=transform
        )
        inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)

        # show one picture from each class
        images, labels = next(iter(inference_loader))
        images = images.squeeze()
        images = torch.swapaxes(images, 1, 2)
        images = torch.swapaxes(images, 2, 3)
        plt.figure(figsize=(10, 8))
        # for i in range(2):
        for idx, i in enumerate([0, 6]):
            plt.subplot(1, 2, idx+1)
            plt.imshow(images[i])
            plt.title(f'Class: {labels[i]}')
            plt.axis('off')
        plt.show()

    def q5_2(self):
        # show the model structure
        # 初始化模型
        model = resnet50(pretrained=False)

        # 修改模型的輸出層
        num_ftrs = model.fc.in_features
        model.fc = nn.Sequential(nn.Linear(num_ftrs, 1, bias=True), nn.Sigmoid())

        # 打印模型結構
        # print the model structure using the summary function
        summary(model, (3, 224, 224), device='cpu')

    def q5_3(self):
        # show the comparison of random erasing and no random erasing
        image_path, _ = QtWidgets.QFileDialog.getOpenFileName()
        if image_path:
            # show the image of 'resnte50_model_accuracy_comparison.jpg'
            # use PIL to plot the image from fileName
            with Image.open(image_path) as image:
                image.show()

    def q5_4(self):
        # inference
        # load model
        model = resnet50(pretrained=False)

        # 修改模型的輸出層
        num_ftrs = model.fc.in_features
        model.fc = nn.Sequential(nn.Linear(num_ftrs, 1, bias=True), nn.Sigmoid())

        # load the trained model parameters
        trained_model_path, _ = QtWidgets.QFileDialog.getOpenFileName()
        model.load_state_dict(torch.load(trained_model_path))

        # test the model
        # load image dataset
        # dataset_path = QtWidgets.QFileDialog.getExistingDirectory()
        # dataset_path = 'E:/YN/opencvdl/Hw2/Dataset_OpenCvDl_Hw2_Q5/dataset'
        transform = transforms.Compose([
            transforms.Resize(224),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            # transforms.Normalize((0.5,), (0.5,))
        ])
        # inference_dataset = torchvision.datasets.ImageFolder(
        #     # root=f"{dataset_path}/inference_dataset", 
        #     # root=dataset_path, 
        #     root=self.imagePath, 
        #     transform=transform
        # )
        # inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)

        # test the model
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()
        # predictions = []
        with torch.no_grad():
            # for images, _ in inference_loader:
            #     images = images.to(device)
            #     outputs = model(images)
            #     predictions.extend(outputs.cpu().numpy().squeeze().tolist())

            # transform the input image
            self.inputImage = Image.fromarray(self.inputImage)
            self.inputImage = transform(self.inputImage).unsqueeze(0).to(device)
            outputs = model(self.inputImage)  # here outputs is a predicted_probability

        # show the prediction result
        # print(predictions)
        # self.PredictionResult.setText(f"Prediction: {predictions[0]}")
        self.PredictionLabel = 'Cat' if outputs[0][0] <= 0.5 else 'Dog'
        self.PredictionResult.setText(f"Prediction: {self.PredictionLabel}")

def main():
    app = QApplication(sys.argv)
    hw2 = QtWidgets.QWidget()
    ui = Ui_Form(hw2)
    # ui.setupUi(hw2)
    hw2.show()
    sys.exit(app.exec_())

    # app = QtWidgets.QApplication(sys.argv)
    # hw1 = QtWidgets.QWidget()
    # ui = Ui_hw1(hw1)
    # # ui.setupUi(hw1)
    # hw1.show()
    # sys.exit(app.exec_())

if __name__ == '__main__':
    main()
